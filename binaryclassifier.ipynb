{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classifier for tumor classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This MLP classifier is designed to classify the presence tumor using the gene expression data.\n",
    "#### Import all the required python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Dataset, selecting the best features and combining it with the PCA transform features so that we dont lose the best features and further decreasing the input set to 6 axis by doing PCA of the combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputdata = pd.read_csv('colonTumor.data');\n",
    "datasets = inputdata.values\n",
    "X = datasets[:,0:2000]\n",
    "Y = datasets[:,2000]\n",
    "\n",
    "X = scale(X)\n",
    "pca = PCA(n_components = 6)\n",
    "selection = SelectKBest(k = 10)\n",
    "\n",
    "# Build estimator from PCA and Univariate selection:\n",
    "combined_features = FeatureUnion([(\"pca\", pca), (\"univ_select\", selection)])\n",
    "\n",
    "# Use combined features to transform dataset:\n",
    "X = combined_features.fit(X,Y).transform(X)\n",
    "\n",
    "# futher transforming to 6 axis by using PCA:\n",
    "X1 = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data spliting and assigning 80% of the dataset to train and further to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.\n",
      "  1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "train = X1[0:40,:]\n",
    "trainlabel = Y[0:40]\n",
    "test = X1[40:61,:]\n",
    "testlabel = Y[40:61]\n",
    "print testlabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Sklearn Neural Network library and training the dataset with the Multi level perceptron classifier for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.89391765\n",
      "Iteration 2, loss = 1.97214958\n",
      "Iteration 3, loss = 0.79953257\n",
      "Iteration 4, loss = 1.13048074\n",
      "Iteration 5, loss = 0.64681703\n",
      "Iteration 6, loss = 0.50062236\n",
      "Iteration 7, loss = 0.41485574\n",
      "Iteration 8, loss = 0.34924516\n",
      "Iteration 9, loss = 0.29506818\n",
      "Iteration 10, loss = 0.26106674\n",
      "Iteration 11, loss = 0.23313207\n",
      "Iteration 12, loss = 0.20913210\n",
      "Iteration 13, loss = 0.18948948\n",
      "Iteration 14, loss = 0.17343546\n",
      "Iteration 15, loss = 0.15974517\n",
      "Iteration 16, loss = 0.14785929\n",
      "Iteration 17, loss = 0.13697493\n",
      "Iteration 18, loss = 0.12679836\n",
      "Iteration 19, loss = 0.11731902\n",
      "Iteration 20, loss = 0.10847839\n",
      "Iteration 21, loss = 0.10004173\n",
      "Iteration 22, loss = 0.09213270\n",
      "Iteration 23, loss = 0.08467106\n",
      "Iteration 24, loss = 0.07780555\n",
      "Iteration 25, loss = 0.07165166\n",
      "Iteration 26, loss = 0.06623482\n",
      "Iteration 27, loss = 0.06130863\n",
      "Iteration 28, loss = 0.05687129\n",
      "Iteration 29, loss = 0.05289023\n",
      "Iteration 30, loss = 0.04925554\n",
      "Iteration 31, loss = 0.04589922\n",
      "Iteration 32, loss = 0.04279084\n",
      "Iteration 33, loss = 0.03995114\n",
      "Iteration 34, loss = 0.03735209\n",
      "Iteration 35, loss = 0.03504630\n",
      "Iteration 36, loss = 0.03289826\n",
      "Iteration 37, loss = 0.03092292\n",
      "Iteration 38, loss = 0.02910911\n",
      "Iteration 39, loss = 0.02743934\n",
      "Iteration 40, loss = 0.02590201\n",
      "Iteration 41, loss = 0.02453326\n",
      "Iteration 42, loss = 0.02332330\n",
      "Iteration 43, loss = 0.02219519\n",
      "Iteration 44, loss = 0.02116248\n",
      "Iteration 45, loss = 0.02019811\n",
      "Iteration 46, loss = 0.01929866\n",
      "Iteration 47, loss = 0.01846703\n",
      "Iteration 48, loss = 0.01769590\n",
      "Iteration 49, loss = 0.01699114\n",
      "Iteration 50, loss = 0.01636136\n",
      "Iteration 51, loss = 0.01574951\n",
      "Iteration 52, loss = 0.01516695\n",
      "Iteration 53, loss = 0.01462117\n",
      "Iteration 54, loss = 0.01414243\n",
      "Iteration 55, loss = 0.01368600\n",
      "Iteration 56, loss = 0.01325793\n",
      "Iteration 57, loss = 0.01284013\n",
      "Iteration 58, loss = 0.01245104\n",
      "Iteration 59, loss = 0.01208520\n",
      "Iteration 60, loss = 0.01174610\n",
      "Iteration 61, loss = 0.01142314\n",
      "Iteration 62, loss = 0.01112162\n",
      "Iteration 63, loss = 0.01083506\n",
      "Iteration 64, loss = 0.01056379\n",
      "Iteration 65, loss = 0.01030336\n",
      "Iteration 66, loss = 0.01005374\n",
      "Iteration 67, loss = 0.00981408\n",
      "Iteration 68, loss = 0.00958707\n",
      "Iteration 69, loss = 0.00937107\n",
      "Iteration 70, loss = 0.00916409\n",
      "Iteration 71, loss = 0.00896737\n",
      "Iteration 72, loss = 0.00877776\n",
      "Iteration 73, loss = 0.00859794\n",
      "Iteration 74, loss = 0.00842485\n",
      "Iteration 75, loss = 0.00825870\n",
      "Iteration 76, loss = 0.00810065\n",
      "Iteration 77, loss = 0.00794808\n",
      "Iteration 78, loss = 0.00780086\n",
      "Iteration 79, loss = 0.00765723\n",
      "Iteration 80, loss = 0.00751929\n",
      "Iteration 81, loss = 0.00738637\n",
      "Iteration 82, loss = 0.00725562\n",
      "Iteration 83, loss = 0.00713200\n",
      "Iteration 84, loss = 0.00701093\n",
      "Iteration 85, loss = 0.00689827\n",
      "Iteration 86, loss = 0.00678313\n",
      "Iteration 87, loss = 0.00667577\n",
      "Iteration 88, loss = 0.00657043\n",
      "Iteration 89, loss = 0.00646852\n",
      "Iteration 90, loss = 0.00637034\n",
      "Iteration 91, loss = 0.00627405\n",
      "Iteration 92, loss = 0.00618189\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.002000\n",
      "Iteration 93, loss = 0.00609316\n",
      "Iteration 94, loss = 0.00601792\n",
      "Iteration 95, loss = 0.00594926\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000400\n",
      "Iteration 96, loss = 0.00588645\n",
      "Iteration 97, loss = 0.00583133\n",
      "Iteration 98, loss = 0.00578175\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000080\n",
      "Iteration 99, loss = 0.00573715\n",
      "Iteration 100, loss = 0.00569749\n",
      "Iteration 101, loss = 0.00566193\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000016\n",
      "Iteration 102, loss = 0.00563003\n",
      "Iteration 103, loss = 0.00560149\n",
      "Iteration 104, loss = 0.00557589\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000003\n",
      "Iteration 105, loss = 0.00555294\n",
      "Iteration 106, loss = 0.00553237\n",
      "Iteration 107, loss = 0.00551391\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 108, loss = 0.00549746\n",
      "Iteration 109, loss = 0.00548268\n",
      "Iteration 110, loss = 0.00546941\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='sgd',learning_rate='adaptive' ,learning_rate_init=0.01, alpha=1e-10,verbose=10,hidden_layer_sizes=(15,200),random_state=1, max_iter =4000)\n",
    "clf1 = clf.fit(train,trainlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model and getting the accuracy of trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  1.]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "class negative       1.00      0.75      0.86        12\n",
      "class positive       0.75      1.00      0.86         9\n",
      "\n",
      "   avg / total       0.89      0.86      0.86        21\n",
      "\n",
      "Accuracy is: 85.7%\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(test)\n",
    "print y_pred\n",
    "\n",
    "target_names = ['class negative', 'class positive']\n",
    "print(classification_report(testlabel, y_pred, target_names=target_names))\n",
    "score = accuracy_score(testlabel , y_pred)\n",
    "print(\n",
    "        \"Accuracy is: %.1f%%\" %\n",
    "        (score* 100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
